diff --git a/include/linux/init_task.h b/include/linux/init_task.h
index 1da4146..77fc43f 100644
--- a/include/linux/init_task.h
+++ b/include/linux/init_task.h
@@ -191,9 +191,6 @@ extern struct task_group root_task_group;
 		.run_list	= LIST_HEAD_INIT(tsk.rt.run_list),	\
 		.time_slice	= RR_TIMESLICE,				\
 	},								\
-	.dummy_se	= {						\
-		.run_list	= LIST_HEAD_INIT(tsk.dummy_se.run_list),\
-	},								\
 	.tasks		= LIST_HEAD_INIT(tsk.tasks),			\
 	INIT_PUSHABLE_TASKS(tsk)					\
 	INIT_CGROUP_SCHED(tsk)						\
diff --git a/include/linux/sched.h b/include/linux/sched.h
old mode 100755
new mode 100644
index 2d7ad36..5e344bb
--- a/include/linux/sched.h
+++ b/include/linux/sched.h
@@ -1167,10 +1167,6 @@ struct sched_rt_entity {
 #endif
 };
 
-struct sched_dummy_entity {
-	struct list_head run_list;
-};
-
 struct sched_dl_entity {
 	struct rb_node	rb_node;
 
@@ -1242,8 +1238,6 @@ struct task_struct {
 	atomic_t usage;
 	unsigned int flags;	/* per process flags, defined below */
 	unsigned int ptrace;
-	
-
 
 #ifdef CONFIG_SMP
 	struct llist_node wake_entry;
@@ -1261,7 +1255,6 @@ struct task_struct {
 	const struct sched_class *sched_class;
 	struct sched_entity se;
 	struct sched_rt_entity rt;
-	struct sched_dummy_entity dummy_se;
 #ifdef CONFIG_CGROUP_SCHED
 	struct task_group *sched_task_group;
 #endif
@@ -1707,22 +1700,6 @@ static inline bool should_numa_migrate_memory(struct task_struct *p,
 }
 #endif
 
-#define MIN_DUMMY_PRIO 131
-#define MAX_DUMMY_PRIO 135
-
-static inline int dummy_prio(int prio)
-{
-	if (prio >= MIN_DUMMY_PRIO && prio <= MAX_DUMMY_PRIO)
-		return 1;
-	return 0;
-}
-
-static inline int dummy_task(struct task_struct *p)
-{
-	return dummy_prio(p->prio);
-}
-
-
 static inline struct pid *task_pid(struct task_struct *task)
 {
 	return task->pids[PIDTYPE_PID].pid;
diff --git a/include/linux/sched/sysctl.h b/include/linux/sched/sysctl.h
index 6b2d93e..596a0e0 100644
--- a/include/linux/sched/sysctl.h
+++ b/include/linux/sched/sysctl.h
@@ -40,9 +40,6 @@ extern unsigned int sysctl_sched_min_granularity;
 extern unsigned int sysctl_sched_wakeup_granularity;
 extern unsigned int sysctl_sched_child_runs_first;
 
-extern unsigned int sysctl_sched_dummy_timeslice;
-extern unsigned int sysctl_sched_dummy_age_threshold;
-
 enum sched_tunable_scaling {
 	SCHED_TUNABLESCALING_NONE,
 	SCHED_TUNABLESCALING_LOG,
diff --git a/kernel/sched/Makefile b/kernel/sched/Makefile
index a3e528e..ab32b7b 100644
--- a/kernel/sched/Makefile
+++ b/kernel/sched/Makefile
@@ -12,7 +12,7 @@ CFLAGS_core.o := $(PROFILING) -fno-omit-frame-pointer
 endif
 
 obj-y += core.o proc.o clock.o cputime.o
-obj-y += idle_task.o fair.o rt.o deadline.o stop_task.o dummy.o
+obj-y += idle_task.o fair.o rt.o deadline.o stop_task.o
 obj-y += wait.o completion.o idle.o
 obj-$(CONFIG_SMP) += cpupri.o cpudeadline.o
 obj-$(CONFIG_SCHED_AUTOGROUP) += auto_group.o
diff --git a/kernel/sched/core.c b/kernel/sched/core.c
index c19e47a..efdca2f 100644
--- a/kernel/sched/core.c
+++ b/kernel/sched/core.c
@@ -1957,10 +1957,7 @@ int sched_fork(unsigned long clone_flags, struct task_struct *p)
 	} else if (rt_prio(p->prio)) {
 		p->sched_class = &rt_sched_class;
 	} else {
-		if (dummy_prio(p->prio)) 
-			p->sched_class = &dummy_sched_class;
-		else
-			p->sched_class = &fair_sched_class;
+		p->sched_class = &fair_sched_class;
 	}
 
 	if (p->sched_class->task_fork)
@@ -3095,10 +3092,7 @@ void rt_mutex_setprio(struct task_struct *p, int prio)
 	} else {
 		if (dl_prio(oldprio))
 			p->dl.dl_boosted = 0;
-		if (dummy_prio(prio))
-			p->sched_class = &dummy_sched_class;
-		else
-			p->sched_class = &fair_sched_class;
+		p->sched_class = &fair_sched_class;
 	}
 
 	p->prio = prio;
@@ -3116,7 +3110,7 @@ out_unlock:
 
 void set_user_nice(struct task_struct *p, long nice)
 {
-	int old_prio, delta, queued, running;
+	int old_prio, delta, queued;
 	unsigned long flags;
 	struct rq *rq;
 
@@ -3138,12 +3132,8 @@ void set_user_nice(struct task_struct *p, long nice)
 		goto out_unlock;
 	}
 	queued = task_on_rq_queued(p);
-	running = task_current(rq, p);
-
 	if (queued)
 		dequeue_task(rq, p, 0);
-	if (running)
-		put_prev_task(rq, p);
 
 	p->static_prio = NICE_TO_PRIO(nice);
 	set_load_weight(p);
@@ -3151,15 +3141,6 @@ void set_user_nice(struct task_struct *p, long nice)
 	p->prio = effective_prio(p);
 	delta = p->prio - old_prio;
 
-	const struct sched_class *prev_class = p->sched_class;
-
-	if (dummy_prio(p->prio))
-		p->sched_class = &dummy_sched_class;
-	else
-		p->sched_class = &fair_sched_class;
-
-	if(running)
-		p->sched_class->set_curr_task(rq);
 	if (queued) {
 		enqueue_task(rq, p, 0);
 		/*
@@ -3169,9 +3150,6 @@ void set_user_nice(struct task_struct *p, long nice)
 		if (delta < 0 || (delta > 0 && task_running(rq, p)))
 			resched_curr(rq);
 	}
-	
-	check_class_changed(rq, p, prev_class, old_prio);
-
 out_unlock:
 	task_rq_unlock(rq, p, &flags);
 }
@@ -3356,15 +3334,10 @@ static void __setscheduler(struct rq *rq, struct task_struct *p,
 		p->sched_class = &dl_sched_class;
 	else if (rt_prio(p->prio))
 		p->sched_class = &rt_sched_class;
-	else {
-		if (dummy_prio(p->prio))
-			p->sched_class = &dummy_sched_class;
-		else
-			p->sched_class = &fair_sched_class;
-	}
+	else
+		p->sched_class = &fair_sched_class;
 }
 
-
 static void
 __getparam_dl(struct task_struct *p, struct sched_attr *attr)
 {
@@ -7096,7 +7069,6 @@ void __init sched_init(void)
 		init_cfs_rq(&rq->cfs);
 		init_rt_rq(&rq->rt, rq);
 		init_dl_rq(&rq->dl, rq);
-		init_dummy_rq(&rq->dummy, rq);
 #ifdef CONFIG_FAIR_GROUP_SCHED
 		root_task_group.shares = ROOT_TASK_GROUP_LOAD;
 		INIT_LIST_HEAD(&rq->leaf_cfs_rq_list);
@@ -7186,10 +7158,7 @@ void __init sched_init(void)
 	/*
 	 * During early bootup we pretend to be a normal task:
 	 */
-	if (unlikely(current->prio >= MIN_DUMMY_PRIO && current->prio <= MAX_DUMMY_PRIO))
-		current->sched_class = &dummy_sched_class;
-	else
-		current->sched_class = &fair_sched_class;
+	current->sched_class = &fair_sched_class;
 
 #ifdef CONFIG_SMP
 	zalloc_cpumask_var(&sched_domains_tmpmask, GFP_NOWAIT);
diff --git a/kernel/sched/dummy.c b/kernel/sched/dummy.c
deleted file mode 100755
index b734a7e..0000000
--- a/kernel/sched/dummy.c
+++ /dev/null
@@ -1,250 +0,0 @@
-/*
- * Dummy scheduling class, mapped to range of 5 levels of SCHED_NORMAL policy
- */
-
-#include "sched.h"
-
-/*
- * Timeslice and age threshold are repsented in jiffies. Default timeslice
- * is 100ms. Both parameters can be tuned from /proc/sys/kernel.
- */
-
-#define DUMMY_TIMESLICE		(100 * HZ / 1000)
-#define DUMMY_AGE_THRESHOLD	(3 * DUMMY_TIMESLICE)
-#define NUMBER_PRIORITY 5
-#define PRIO_OFFSET 11
-
-
-
-unsigned int sysctl_sched_dummy_timeslice = DUMMY_TIMESLICE;
-static inline unsigned int get_timeslice(void)
-{
-	return sysctl_sched_dummy_timeslice;
-}
-
-unsigned int sysctl_sched_dummy_age_threshold = DUMMY_AGE_THRESHOLD;
-static inline unsigned int get_age_threshold(void)
-{
-	return sysctl_sched_dummy_age_threshold;
-}
-
-/*
- * Init
- */
-
-void init_dummy_rq(struct dummy_rq *dummy_rq, struct rq *rq)
-{
-	//init all queues
-	int i;
-	for(i = 0; i<NUMBER_PRIORITY; i++){
-		INIT_LIST_HEAD(&dummy_rq->queues[i]);
-	}
-	dummy_rq->tick_time = 0;
-}
-
-/*
- * Helper functions
- */
-  
-/*
-Check if there is at least one non-empty list
-*/
-static int lists_empty(struct list_head lists[]){
-	int ret = 1;
-	int i;
-	for(i = 0; i<NUMBER_PRIORITY; i++){
-		if(!list_empty(&lists[i])){
-			ret = 0;
-		}
-	}
-	return ret;
-}
-
-
-static inline struct task_struct *dummy_task_of(struct sched_dummy_entity *dummy_se)
-{
-	return container_of(dummy_se, struct task_struct, dummy_se);
-}
-
-static inline void _enqueue_task_dummy(struct list_head *queue, struct task_struct *p)
-{
-	struct sched_dummy_entity *dummy_se = &p->dummy_se;
-	list_add_tail(&dummy_se->run_list, queue);
-}
-
-static inline void _dequeue_task_dummy(struct task_struct *p)
-{
-	struct sched_dummy_entity *dummy_se = &p->dummy_se;
-	list_del_init(&dummy_se->run_list);
-}
-
-/*
- * Scheduling class functions to implement
- */
-
-static void enqueue_task_dummy(struct rq *rq, struct task_struct *p, int flags)
-{
-	long prio = p->prio-PRIO_OFFSET;
-	struct list_head *queue = &rq->dummy.queues[prio];
-	_enqueue_task_dummy(queue, p);
-	add_nr_running(rq,1);
-}
-
-static void dequeue_task_dummy(struct rq *rq, struct task_struct *p, int flags)
-{
-	_dequeue_task_dummy(p);
-	sub_nr_running(rq,1);
-}
-
-static void yield_task_dummy(struct rq *rq)
-{
-	long prio_curr = rq->curr->prio;
-	_dequeue_task_dummy(rq->curr);
-	_enqueue_task_dummy(&rq->dummy.queues[prio_curr-PRIO_OFFSET], rq->curr);
-	resched_curr(rq);
-}
-
-static void check_preempt_curr_dummy(struct rq *rq, struct task_struct *p, int flags)
-{
-	long prio = p->prio; 
-	if(rq->curr->prio > prio){
-		yield_task_dummy(rq);
-	}
-	
-}
-
-static struct task_struct *pick_next_task_dummy(struct rq *rq, struct task_struct* prev)
-{
-	struct dummy_rq *dummy_rq = &rq->dummy;
-	struct sched_dummy_entity *next;
-	
-	if(!lists_empty(dummy_rq->queues)) {
-	
-		//search the nonempty list with the higher priority
-		int i = 0;
-		while( list_empty(&dummy_rq->queues[i]) && i<NUMBER_PRIORITY){
-			i++;
-		}
-		next = list_first_entry(&dummy_rq->queues[i], struct sched_dummy_entity, run_list);
-                put_prev_task(rq, prev);
-	
-
-	return dummy_task_of(next);
-	} else {
-		return NULL;
-	}
-}
-
-
-static void put_prev_task_dummy(struct rq *rq, struct task_struct *prev)
-{
-}
-
-static void set_curr_task_dummy(struct rq *rq)
-{
-}
-
-static void task_tick_dummy(struct rq *rq, struct task_struct *curr, int queued)
-{
-
-	struct sched_dummy_entity *se= NULL;
-	struct dummy_rq *dummy_rq = &rq->dummy;
-	struct list_head *queue;
-	struct list_head *next = NULL;
-	// premption due to running task's timeslice expiry
-	struct task_struct *task;
-	dummy_rq->time_slice++;
-	
-
-	if(dummy_rq->time_slice>= DUMMY_TIMESLICE){
-		yield_task_dummy(rq);
-	}
-	//prevent the starvation
-	int i;
-	for(i = 0; i<NUMBER_PRIORITY; i++){
-		queue = &dummy_rq->queues[i];
-		list_for_each_entry(se, queue, run_list){
-			dummy_rq->tick_time++;
-			if(dummy_rq->tick_time>DUMMY_AGE_THRESHOLD){
-				dummy_rq->tick_time = 0;
-				task = dummy_task_of(se);
-				if(task->prio > PRIO_OFFSET){
-					task->prio--;
-					dequeue_task_dummy(rq, task, 0);
-					enqueue_task_dummy(rq, task, 0);
-				}
-				
-			}
-		}
-
-
-
-}
-}
-
-static void switched_from_dummy(struct rq *rq, struct task_struct *p)
-{
-}
-
-static void switched_to_dummy(struct rq *rq, struct task_struct *p)
-{
-}
-
-static void prio_changed_dummy(struct rq*rq, struct task_struct *p, int oldprio)
-{
-	rq->curr->prio = p->prio;
-}
-
-static unsigned int get_rr_interval_dummy(struct rq* rq, struct task_struct *p)
-{
-	return get_timeslice();
-}
-#ifdef CONFIG_SMP
-/*
- * SMP related functions	
- */
-
-static inline int select_task_rq_dummy(struct task_struct *p, int cpu, int sd_flags, int wake_flags)
-{
-	int new_cpu = smp_processor_id();
-	
-	return new_cpu; //set assigned CPU to zero
-}
-
-
-static void set_cpus_allowed_dummy(struct task_struct *p,  const struct cpumask *new_mask)
-{
-}
-#endif
-/*
- * Scheduling class
- */
-static void update_curr_dummy(struct rq*rq)
-{
-}
-const struct sched_class dummy_sched_class = {
-	.next			= &idle_sched_class,
-	.enqueue_task		= enqueue_task_dummy,
-	.dequeue_task		= dequeue_task_dummy,
-	.yield_task		= yield_task_dummy,
-
-	.check_preempt_curr	= check_preempt_curr_dummy,
-	
-	.pick_next_task		= pick_next_task_dummy,
-	.put_prev_task		= put_prev_task_dummy,
-
-#ifdef CONFIG_SMP
-	.select_task_rq		= select_task_rq_dummy,
-	.set_cpus_allowed	= set_cpus_allowed_dummy,
-#endif
-
-	.set_curr_task		= set_curr_task_dummy,
-	.task_tick		= task_tick_dummy,
-
-	.switched_from		= switched_from_dummy,
-	.switched_to		= switched_to_dummy,
-	.prio_changed		= prio_changed_dummy,
-
-	.get_rr_interval	= get_rr_interval_dummy,
-	.update_curr		= update_curr_dummy,
-};
diff --git a/kernel/sched/fair.c b/kernel/sched/fair.c
index 8a6c1d2..ef2b104 100644
--- a/kernel/sched/fair.c
+++ b/kernel/sched/fair.c
@@ -3033,7 +3033,6 @@ pick_next_entity(struct cfs_rq *cfs_rq, struct sched_entity *curr)
 
 	se = left; /* ideally we run the leftmost entity */
 
-	BUG_ON(!se);
 	/*
 	 * Avoid running the skip buddy, if running something else can
 	 * be done without getting too unfair.
@@ -4897,8 +4896,7 @@ simple:
 #endif
 
 	if (!cfs_rq->nr_running)
-		return NULL;
-//		goto idle;
+		goto idle;
 
 	put_prev_task(rq, prev);
 
@@ -7932,7 +7930,7 @@ static unsigned int get_rr_interval_fair(struct rq *rq, struct task_struct *task
  * All the scheduling class methods:
  */
 const struct sched_class fair_sched_class = {
-	.next			= &dummy_sched_class,
+	.next			= &idle_sched_class,
 	.enqueue_task		= enqueue_task_fair,
 	.dequeue_task		= dequeue_task_fair,
 	.yield_task		= yield_task_fair,
diff --git a/kernel/sched/sched.h b/kernel/sched/sched.h
old mode 100755
new mode 100644
index 671db9a..2df8ef0
--- a/kernel/sched/sched.h
+++ b/kernel/sched/sched.h
@@ -468,16 +468,6 @@ struct dl_rq {
 #endif
 };
 
-struct dummy_rq {
-	//struct list_head queue;
-	
-	//replace the fifo queue by 5 fifo queues, one for each priority.
-	struct list_head queues[5];
-	int time_slice;
-	int tick_time;
-	
-};
-
 #ifdef CONFIG_SMP
 
 /*
@@ -559,7 +549,7 @@ struct rq {
 	struct cfs_rq cfs;
 	struct rt_rq rt;
 	struct dl_rq dl;
-	struct dummy_rq dummy;
+
 #ifdef CONFIG_FAIR_GROUP_SCHED
 	/* list of leaf cfs_rq on this cpu: */
 	struct list_head leaf_cfs_rq_list;
@@ -1165,7 +1155,6 @@ extern const struct sched_class stop_sched_class;
 extern const struct sched_class dl_sched_class;
 extern const struct sched_class rt_sched_class;
 extern const struct sched_class fair_sched_class;
-extern const struct sched_class dummy_sched_class;
 extern const struct sched_class idle_sched_class;
 
 
@@ -1519,7 +1508,6 @@ extern void print_rt_stats(struct seq_file *m, int cpu);
 extern void init_cfs_rq(struct cfs_rq *cfs_rq);
 extern void init_rt_rq(struct rt_rq *rt_rq, struct rq *rq);
 extern void init_dl_rq(struct dl_rq *dl_rq, struct rq *rq);
-extern void init_dummy_rq(struct dummy_rq *dummy_rq, struct rq *rq);
 
 extern void cfs_bandwidth_usage_inc(void);
 extern void cfs_bandwidth_usage_dec(void);
diff --git a/kernel/sysctl.c b/kernel/sysctl.c
index 24b39cd..15f2511 100644
--- a/kernel/sysctl.c
+++ b/kernel/sysctl.c
@@ -312,20 +312,6 @@ static struct ctl_table kern_table[] = {
 		.extra1		= &min_wakeup_granularity_ns,
 		.extra2		= &max_wakeup_granularity_ns,
 	},
-	{
-		.procname	= "sched_dummy_timeslice",
-		.data		= &sysctl_sched_dummy_timeslice,
-		.maxlen		= sizeof(unsigned int),
-		.mode		= 0644,
-		.proc_handler	= proc_dointvec,
-	},
-	{
-		.procname	= "sched_dummy_age_threshold",
-		.data		= &sysctl_sched_dummy_age_threshold,
-		.maxlen		= sizeof(unsigned int),
-		.mode		= 0644,
-		.proc_handler	= proc_dointvec,
-	},
 #ifdef CONFIG_SMP
 	{
 		.procname	= "sched_tunable_scaling",
